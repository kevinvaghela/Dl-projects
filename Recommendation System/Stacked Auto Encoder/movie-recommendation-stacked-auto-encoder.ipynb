{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Part 1 - Data Preprocessing","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":"### Importing the Libraries","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import Variable\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"### Importing the Dataset","metadata":{}},{"cell_type":"code","source":"training_set = pd.read_csv('../input/users-movies-ratings/ml-100k/ml-100k/u1.base', delimiter='\\t')\ntraining_set = np.array(training_set, dtype='int')\ntest_set = pd.read_csv('../input/users-movies-ratings/ml-100k/ml-100k/u1.test', delimiter='\\t')\ntest_set = np.array(test_set, dtype='int')","metadata":{"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"### Getting the number of users and movies","metadata":{}},{"cell_type":"code","source":"nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\nnb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))","metadata":{"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"nb_users, nb_movies","metadata":{"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"(943, 1682)"},"metadata":{}}]},{"cell_type":"markdown","source":"### Converting the data into an array with users in lines and movies in columns","metadata":{}},{"cell_type":"code","source":"def convert(data):\n    new_data=[]\n    for id_users in range(1, nb_users+1):\n        id_movies = data[:,1][data[:,0] == id_users]\n        id_movies = data[:,1][data[:,0] == id_users]\n        id_ratings = data[:,2][data[:,0] == id_users]\n        ratings = np.zeros(nb_movies)\n        ratings[id_movies - 1] = id_ratings\n        new_data.append(list(ratings))\n    return new_data\n\ntraining_set = convert(training_set)\ntest_set = convert(test_set)","metadata":{"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### Converting the data into Torch Tensor","metadata":{}},{"cell_type":"code","source":"training_set = torch.FloatTensor(training_set)\ntest_set = torch.FloatTensor(test_set)","metadata":{"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Part 2 - Creating model Architecture and Training","metadata":{}},{"cell_type":"code","source":"class SAE(nn.Module):\n    \n    def __init__(self,):\n        super(SAE, self).__init__()\n        self.fc1 = nn.Linear(nb_movies, 20)\n        self.fc2 = nn.Linear(20,10)\n        self.fc3 = nn.Linear(10,20)\n        self.fc4 = nn.Linear(20, nb_movies)\n        self.activation = nn.Sigmoid()\n        \n    def forward(self, x):\n        x = self.activation(self.fc1(x))\n        x = self.activation(self.fc2(x))\n        x = self.activation(self.fc3(x))\n        x = self.fc4(x)\n        return x","metadata":{"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"sae = SAE()\ncriterion = nn.MSELoss()\noptimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5)","metadata":{"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"### Training the SAE( Stacked auto encoder)","metadata":{}},{"cell_type":"code","source":"nb_epoch = 200\nfor epoch in range(1, nb_epoch+1):\n    train_loss = 0\n    s = 0.\n    for id_user in range(nb_users):\n        inputs = Variable(training_set[id_user]).unsqueeze(0)\n        target = inputs.clone()\n        if torch.sum(target.data > 0) > 0:\n            output = sae(inputs)\n            target.require_grad = False\n            output[target == 0] = 0\n            loss = criterion(output, target)\n            mean_corrector = nb_movies/float(torch.sum(target.data>0)+1e-10)\n            loss.backward()\n            train_loss += np.sqrt(loss.data*mean_corrector)\n            s += 1.\n            optimizer.step()\n    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))","metadata":{"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"epoch: 1 loss: tensor(1.7716)\nepoch: 2 loss: tensor(1.0965)\nepoch: 3 loss: tensor(1.0535)\nepoch: 4 loss: tensor(1.0383)\nepoch: 5 loss: tensor(1.0309)\nepoch: 6 loss: tensor(1.0267)\nepoch: 7 loss: tensor(1.0240)\nepoch: 8 loss: tensor(1.0219)\nepoch: 9 loss: tensor(1.0207)\nepoch: 10 loss: tensor(1.0195)\nepoch: 11 loss: tensor(1.0189)\nepoch: 12 loss: tensor(1.0185)\nepoch: 13 loss: tensor(1.0177)\nepoch: 14 loss: tensor(1.0178)\nepoch: 15 loss: tensor(1.0173)\nepoch: 16 loss: tensor(1.0168)\nepoch: 17 loss: tensor(1.0167)\nepoch: 18 loss: tensor(1.0164)\nepoch: 19 loss: tensor(1.0162)\nepoch: 20 loss: tensor(1.0161)\nepoch: 21 loss: tensor(1.0162)\nepoch: 22 loss: tensor(1.0158)\nepoch: 23 loss: tensor(1.0159)\nepoch: 24 loss: tensor(1.0160)\nepoch: 25 loss: tensor(1.0158)\nepoch: 26 loss: tensor(1.0156)\nepoch: 27 loss: tensor(1.0152)\nepoch: 28 loss: tensor(1.0151)\nepoch: 29 loss: tensor(1.0139)\nepoch: 30 loss: tensor(1.0121)\nepoch: 31 loss: tensor(1.0101)\nepoch: 32 loss: tensor(1.0094)\nepoch: 33 loss: tensor(1.0062)\nepoch: 34 loss: tensor(1.0061)\nepoch: 35 loss: tensor(1.0016)\nepoch: 36 loss: tensor(1.0010)\nepoch: 37 loss: tensor(0.9977)\nepoch: 38 loss: tensor(0.9967)\nepoch: 39 loss: tensor(0.9926)\nepoch: 40 loss: tensor(0.9923)\nepoch: 41 loss: tensor(0.9876)\nepoch: 42 loss: tensor(0.9894)\nepoch: 43 loss: tensor(0.9877)\nepoch: 44 loss: tensor(0.9855)\nepoch: 45 loss: tensor(0.9816)\nepoch: 46 loss: tensor(0.9855)\nepoch: 47 loss: tensor(0.9847)\nepoch: 48 loss: tensor(0.9832)\nepoch: 49 loss: tensor(0.9794)\nepoch: 50 loss: tensor(0.9790)\nepoch: 51 loss: tensor(0.9720)\nepoch: 52 loss: tensor(0.9740)\nepoch: 53 loss: tensor(0.9755)\nepoch: 54 loss: tensor(0.9836)\nepoch: 55 loss: tensor(0.9795)\nepoch: 56 loss: tensor(0.9771)\nepoch: 57 loss: tensor(0.9724)\nepoch: 58 loss: tensor(0.9728)\nepoch: 59 loss: tensor(0.9693)\nepoch: 60 loss: tensor(0.9679)\nepoch: 61 loss: tensor(0.9621)\nepoch: 62 loss: tensor(0.9626)\nepoch: 63 loss: tensor(0.9717)\nepoch: 64 loss: tensor(0.9680)\nepoch: 65 loss: tensor(0.9635)\nepoch: 66 loss: tensor(0.9620)\nepoch: 67 loss: tensor(0.9616)\nepoch: 68 loss: tensor(0.9588)\nepoch: 69 loss: tensor(0.9549)\nepoch: 70 loss: tensor(0.9576)\nepoch: 71 loss: tensor(0.9554)\nepoch: 72 loss: tensor(0.9544)\nepoch: 73 loss: tensor(0.9543)\nepoch: 74 loss: tensor(0.9537)\nepoch: 75 loss: tensor(0.9512)\nepoch: 76 loss: tensor(0.9522)\nepoch: 77 loss: tensor(0.9496)\nepoch: 78 loss: tensor(0.9496)\nepoch: 79 loss: tensor(0.9465)\nepoch: 80 loss: tensor(0.9479)\nepoch: 81 loss: tensor(0.9479)\nepoch: 82 loss: tensor(0.9464)\nepoch: 83 loss: tensor(0.9467)\nepoch: 84 loss: tensor(0.9445)\nepoch: 85 loss: tensor(0.9426)\nepoch: 86 loss: tensor(0.9435)\nepoch: 87 loss: tensor(0.9414)\nepoch: 88 loss: tensor(0.9429)\nepoch: 89 loss: tensor(0.9389)\nepoch: 90 loss: tensor(0.9411)\nepoch: 91 loss: tensor(0.9385)\nepoch: 92 loss: tensor(0.9398)\nepoch: 93 loss: tensor(0.9372)\nepoch: 94 loss: tensor(0.9386)\nepoch: 95 loss: tensor(0.9358)\nepoch: 96 loss: tensor(0.9372)\nepoch: 97 loss: tensor(0.9353)\nepoch: 98 loss: tensor(0.9364)\nepoch: 99 loss: tensor(0.9341)\nepoch: 100 loss: tensor(0.9352)\nepoch: 101 loss: tensor(0.9328)\nepoch: 102 loss: tensor(0.9343)\nepoch: 103 loss: tensor(0.9324)\nepoch: 104 loss: tensor(0.9333)\nepoch: 105 loss: tensor(0.9313)\nepoch: 106 loss: tensor(0.9326)\nepoch: 107 loss: tensor(0.9314)\nepoch: 108 loss: tensor(0.9319)\nepoch: 109 loss: tensor(0.9303)\nepoch: 110 loss: tensor(0.9310)\nepoch: 111 loss: tensor(0.9293)\nepoch: 112 loss: tensor(0.9305)\nepoch: 113 loss: tensor(0.9284)\nepoch: 114 loss: tensor(0.9295)\nepoch: 115 loss: tensor(0.9277)\nepoch: 116 loss: tensor(0.9285)\nepoch: 117 loss: tensor(0.9271)\nepoch: 118 loss: tensor(0.9312)\nepoch: 119 loss: tensor(0.9327)\nepoch: 120 loss: tensor(0.9315)\nepoch: 121 loss: tensor(0.9301)\nepoch: 122 loss: tensor(0.9314)\nepoch: 123 loss: tensor(0.9299)\nepoch: 124 loss: tensor(0.9295)\nepoch: 125 loss: tensor(0.9281)\nepoch: 126 loss: tensor(0.9274)\nepoch: 127 loss: tensor(0.9272)\nepoch: 128 loss: tensor(0.9267)\nepoch: 129 loss: tensor(0.9259)\nepoch: 130 loss: tensor(0.9252)\nepoch: 131 loss: tensor(0.9249)\nepoch: 132 loss: tensor(0.9340)\nepoch: 133 loss: tensor(0.9349)\nepoch: 134 loss: tensor(0.9332)\nepoch: 135 loss: tensor(0.9293)\nepoch: 136 loss: tensor(0.9349)\nepoch: 137 loss: tensor(0.9347)\nepoch: 138 loss: tensor(0.9339)\nepoch: 139 loss: tensor(0.9309)\nepoch: 140 loss: tensor(0.9319)\nepoch: 141 loss: tensor(0.9298)\nepoch: 142 loss: tensor(0.9306)\nepoch: 143 loss: tensor(0.9279)\nepoch: 144 loss: tensor(0.9281)\nepoch: 145 loss: tensor(0.9273)\nepoch: 146 loss: tensor(0.9259)\nepoch: 147 loss: tensor(0.9248)\nepoch: 148 loss: tensor(0.9244)\nepoch: 149 loss: tensor(0.9239)\nepoch: 150 loss: tensor(0.9247)\nepoch: 151 loss: tensor(0.9258)\nepoch: 152 loss: tensor(0.9277)\nepoch: 153 loss: tensor(0.9289)\nepoch: 154 loss: tensor(0.9293)\nepoch: 155 loss: tensor(0.9304)\nepoch: 156 loss: tensor(0.9304)\nepoch: 157 loss: tensor(0.9278)\nepoch: 158 loss: tensor(0.9291)\nepoch: 159 loss: tensor(0.9283)\nepoch: 160 loss: tensor(0.9295)\nepoch: 161 loss: tensor(0.9267)\nepoch: 162 loss: tensor(0.9286)\nepoch: 163 loss: tensor(0.9252)\nepoch: 164 loss: tensor(0.9252)\nepoch: 165 loss: tensor(0.9240)\nepoch: 166 loss: tensor(0.9246)\nepoch: 167 loss: tensor(0.9246)\nepoch: 168 loss: tensor(0.9264)\nepoch: 169 loss: tensor(0.9224)\nepoch: 170 loss: tensor(0.9244)\nepoch: 171 loss: tensor(0.9219)\nepoch: 172 loss: tensor(0.9222)\nepoch: 173 loss: tensor(0.9219)\nepoch: 174 loss: tensor(0.9208)\nepoch: 175 loss: tensor(0.9216)\nepoch: 176 loss: tensor(0.9205)\nepoch: 177 loss: tensor(0.9192)\nepoch: 178 loss: tensor(0.9206)\nepoch: 179 loss: tensor(0.9191)\nepoch: 180 loss: tensor(0.9195)\nepoch: 181 loss: tensor(0.9175)\nepoch: 182 loss: tensor(0.9179)\nepoch: 183 loss: tensor(0.9173)\nepoch: 184 loss: tensor(0.9178)\nepoch: 185 loss: tensor(0.9166)\nepoch: 186 loss: tensor(0.9173)\nepoch: 187 loss: tensor(0.9166)\nepoch: 188 loss: tensor(0.9244)\nepoch: 189 loss: tensor(0.9266)\nepoch: 190 loss: tensor(0.9275)\nepoch: 191 loss: tensor(0.9247)\nepoch: 192 loss: tensor(0.9235)\nepoch: 193 loss: tensor(0.9217)\nepoch: 194 loss: tensor(0.9216)\nepoch: 195 loss: tensor(0.9226)\nepoch: 196 loss: tensor(0.9219)\nepoch: 197 loss: tensor(0.9194)\nepoch: 198 loss: tensor(0.9183)\nepoch: 199 loss: tensor(0.9155)\nepoch: 200 loss: tensor(0.9169)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Part 3 - Test on test set","metadata":{}},{"cell_type":"code","source":"test_loss = 0\ns = 0.\nfor id_user in range(nb_users):\n    inputs = Variable(training_set[id_user]).unsqueeze(0)\n    target = Variable(test_set[id_user])\n    if torch.sum(target.data > 0) >0:\n        output = sae(inputs)\n        target.require_grad = False\n        output[(target == 0).unsqueeze(0)] = 0\n        loss = criterion(output, target)\n        mean_collector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n        test_loss += np.sqrt(loss.data*mean_corrector)\n        s += 1.\nprint('test loss: '+str(test_loss/s))    ","metadata":{"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"test loss: tensor(0.4324)\n","output_type":"stream"}]}]}